dataset:
  observation_fieldnames:
     - index
     - sentence
     - lemma_sentence
     - upos_sentence
     - xpos_sentence
     - morph
     - head_indices
     - governance_relations
     - secondary_relations
     - extra_info
     - embeddings
  corpus:
    name: en_ewt-ud
    root: example/data/en_ewt-ud/
    train_path: en_ewt-ud-train.conllu
    dev_path: en_ewt-ud-dev.conllu
    test_path: en_ewt-ud-test.conllu
  embeddings:
    type: token #{token,subword}
    root: example/data/en_ewt-ud/ 
    train_path: en_ewt-ud-train.bert-base-layers.hdf5
    dev_path: en_ewt-ud-dev.bert-base-layers.hdf5
    test_path: en_ewt-ud-test.bert-base-layers.hdf5
    embedding_dim: 768 # ELMo word embedding dim    
  sub_dim:
    do_sub_dim: False
    dim_num: 384
    dim_file: dim.tsv # either the real file, or NONE, this will select the first dim_num dimensions
  batch_size: 100
  dataset_size: 40000
model:
  hidden_dim: 768 # ELMo hidden dim
  model_type: BERT-disk # BERT-disk, ELMo-disk, 
  use_disk: True
  model_layer: 1 # BERT-base: {1,...,12}; ELMo: {1,2,3}
probe:
  task_signature: word_label # word, word_pair
  task_name: corrupted-part-of-speech
  maximum_rank: 1000
  psd_parameters: True
  diagonal: False
  hidden_layers: 0
  dropout: 0
  params_path: predictor.params
  misc:
    corrupted_token_percent: 0.0
probe_training:
  epochs: 40
  loss: cross-entropy
  weight_decay: 0.0
reporting:
  root: ./results
  observation_paths:
    train_path: train.observations
    dev_path: dev.observations
    test_path: test.observations
  prediction_paths:
    train_path: train.predictions
    dev_path: dev.predictions
    test_path: test.predictions
  reporting_methods:
    - label_accuracy
